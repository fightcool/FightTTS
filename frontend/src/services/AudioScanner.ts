import { AudioSample, AudioConfig, AudioScanResult } from '../types/audio';

export interface AudioScannerConfig {
  basePath: string;
  voiceSamplesPath: string;
  emotionSamplesPath: string;
  supportedFormats: string[];
  maxFileSize: number;
}

export class AudioScanner {
  private config: AudioScannerConfig;
  private audioCache: Map<string, AudioSample> = new Map();
  private isInitialized: boolean = false;
  private scanningInProgress: boolean = false;

  constructor(config: AudioConfig) {
    this.config = config;
  }

  // åˆå§‹åŒ–æ‰«ææœåŠ¡
  async initialize(): Promise<void> {
    if (this.isInitialized) return;

    console.log('ğŸ” åˆå§‹åŒ–éŸ³é¢‘æ‰«ææœåŠ¡...');
    this.isInitialized = true;

    // æ‰§è¡Œåˆå§‹æ‰«æ
    await this.scanAllAudioFiles();
  }

  // æ‰§è¡Œå®Œæ•´éŸ³é¢‘æ‰«æ
  async scanAllAudioFiles(): Promise<AudioScanResult> {
    if (this.scanningInProgress) {
      throw new Error('æ‰«ææ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨åå†è¯•');
    }

    this.scanningInProgress = true;
    const startTime = Date.now();

    try {
      // ä½¿ç”¨æ–°çš„APIç«¯ç‚¹æ‰«æéŸ³é¢‘æ ·æœ¬
      const response = await fetch('http://127.0.0.1:8000/api/audio-samples/scan');

      if (!response.ok) {
        console.warn(`æ— æ³•è®¿é—®éŸ³é¢‘æ‰«æAPI: ${response.status}`);
        return {
          total: 0,
          voiceSamples: [],
          emotionSamples: [],
          errors: [`APIè¯·æ±‚å¤±è´¥: ${response.status}`],
          scanTime: Date.now() - startTime
        };
      }

      const scanResult = await response.json();
      console.log('æ‰«æç»“æœ:', scanResult);

      const voiceSamples: AudioSample[] = (scanResult.voice_samples || []).map((sample: any) => ({
        id: sample.id,
        name: sample.name,
        category: 'voice' as const,
        subcategory: sample.subcategory,
        fileName: sample.fileName,
        // åœ¨å¼€å‘ç¯å¢ƒä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œè®©Viteä»£ç†å¤„ç†ï¼›ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å®Œæ•´URL
        filePath: import.meta.env.DEV ? sample.filePath : `http://127.0.0.1:8000${sample.filePath}`,
        duration: sample.duration || 0,
        description: sample.description,
        tags: sample.tags || [],
        created: new Date(sample.metadata?.created || Date.now()),
        metadata: sample.metadata
      }));

      const emotionSamples: AudioSample[] = (scanResult.emotion_samples || []).map((sample: any) => ({
        id: sample.id,
        name: sample.name,
        category: 'emotion' as const,
        subcategory: sample.subcategory,
        fileName: sample.fileName,
        // åœ¨å¼€å‘ç¯å¢ƒä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œè®©Viteä»£ç†å¤„ç†ï¼›ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å®Œæ•´URL
        filePath: import.meta.env.DEV ? sample.filePath : `http://127.0.0.1:8000${sample.filePath}`,
        duration: sample.duration || 0,
        description: sample.description,
        tags: sample.tags || [],
        created: new Date(sample.metadata?.created || Date.now()),
        metadata: sample.metadata
      }));

      const totalTime = Date.now() - startTime;
      const total = voiceSamples.length + emotionSamples.length;

      console.log(`ğŸ‰ éŸ³é¢‘æ‰«æå®Œæˆï¼Œå…±å‘ç° ${total} ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œè€—æ—¶ ${totalTime}ms`);

      const result: AudioScanResult = {
        total,
        voiceSamples,
        emotionSamples,
        errors: [],
        scanTime: totalTime
      };

      // æ¸…ç†æ—§çš„ç¼“å­˜
      this.cleanupOldCache();

      // æ›´æ–°ç¼“å­˜
      this.updateAudioCache(voiceSamples);
      this.updateAudioCache(emotionSamples);

      return result;

    } catch (error) {
      console.error('éŸ³é¢‘æ‰«æå¤±è´¥:', error);
      return {
        total: 0,
        voiceSamples: [],
        emotionSamples: [],
        errors: [error instanceof Error ? error.message : 'æ‰«æå¤±è´¥'],
        scanTime: Date.now() - startTime
      };
    } finally {
      this.scanningInProgress = false;
    }
  }



  // æ›´æ–°éŸ³é¢‘ç¼“å­˜
  private updateAudioCache(audioSamples: AudioSample[]): void {
    audioSamples.forEach(audio => {
      this.audioCache.set(audio.id, audio);
    });
  }

  // æ¸…ç†æ—§çš„ç¼“å­˜
  private cleanupOldCache(): void {
    // æ£€æŸ¥ç¼“å­˜ä¸­çš„æ–‡ä»¶æ˜¯å¦ä»ç„¶å­˜åœ¨
    const cachedIds = Array.from(this.audioCache.keys());

    cachedIds.forEach(id => {
      const audio = this.audioCache.get(id);
      if (audio && !audio.filePath) {
        console.warn(`æ¸…ç†æ— æ•ˆçš„éŸ³é¢‘ç¼“å­˜: ${audio.id}`);
        this.audioCache.delete(id);
      }
    });
  }

  // è·å–æ‰€æœ‰éŸ³é¢‘
  getAllAudioSamples(): AudioSample[] {
    return Array.from(this.audioCache.values());
  }

  // æŒ‰åˆ†ç±»è·å–éŸ³é¢‘
  getAudioSamplesByCategory(category: 'voice' | 'emotion'): AudioSample[] {
    return Array.from(this.audioCache.values()).filter(audio => audio.category === category);
  }

  // æŒ‰IDè·å–éŸ³é¢‘
  getAudioById(id: string): AudioSample | undefined {
    return this.audioCache.get(id);
  }

  // æ¸…é™¤ç¼“å­˜
  clearCache(): void {
    this.audioCache.clear();
  }

  // åˆ·æ–°æ‰«æ
  async refreshCache(): Promise<AudioScanResult> {
    this.clearCache();
    return this.scanAllAudioFiles();
  }
}